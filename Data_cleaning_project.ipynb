{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns',None) #this will display all the columns without shrinking\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"GSAF5.csv\", engine = 'python')  #encoding = 'cp1252'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Investigating a bit further to check how similar are the columns \"Case Number.1\" and \"Case Number.2\" and then make a decision after. Like this:\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking to know if both columns are equal in values\n",
    "df['Case Number'].equals(df['Case Number.1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# checking to know the correlation of values in the the columns\n",
    "df['Case Number'].isin(df['Case Number.1']).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = round(((3213/5992)*100), 1)\n",
    "print(\"Percentage of missing values in the Time columns is {}%, which indicate that it's more than 50% of the dataset So I decided to drop it\".format(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:Blue'> Difference is indeed very small so i decided to just drop it! Same for the \"href column\". Regarding missing values, a rule of thumb in the Data Analysis world is that if 30% or more of the data is missing you can drop the entire column. This is just a rule of thumb. Each case is a case of course. </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping of columns that are not relevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''the columns unnamed 22 and unnamed 23 have only 1 and 2 against 5992 values values so i have to drop them and href have the same values with href formula\n",
    "column Case Number1, Case Number2 have the same values with the case number so i decided to drop them too'''\n",
    "df = df.drop(['Unnamed: 22', 'Unnamed: 23', 'href','Case Number.1', 'Case Number.2','Time'],axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Renaming of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming columns\n",
    "df.rename(columns={'Sex ':'Sex', 'Species ': 'Species','original order':'Original_order','Fatal (Y/N)':'Fatal'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#getting the value count from Species without NAN\n",
    "df['Species'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replacing characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fou u in df['href formula']:\n",
    "#     print(u)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find =df[(df['href formula']== 'pdf-directory/2013.05.27.b-Ena.pdf')]\n",
    "find"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['href formula'] = df['href formula'].str.replace('pdf_directory2014.01.04-Riano.pdf', 'http://sharkattackfile.net/spreadsheets/pdf_directory2014.01.04-Riano.pdf').str.replace(' ','').str.replace(',','.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set(df['Country'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing characters in column's values\n",
    "df['Country'] = df['Country'].str.replace('?', '').str.replace('/',' & ').str.replace('Between','')\n",
    "df['Country'] = df['Country'].str.replace('\\(',' ').str.replace('\\)',' ')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set(df['Activity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Activity']= df['Activity'].str.replace('�','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# set(df['Age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Age'] = df['Age'].str.replace('�', '0').str.replace('s', '').str.replace(' ', '').str.replace('?', '').str.replace('middle-age','45').replace('2326','24').replace('3230','31')\n",
    "df['Age'] = df['Age'].str.replace('young','25').str.replace('&','').str.replace('\\(',' ').str.replace('\\)',' ').str.replace('18month','2').replace('25or28','26').replace('3326','31')\n",
    "df['Age'] = df['Age'].str.replace('','').replace('10or12','11').replace('12or13','12').replace('13or14','13').replace('13or18','15').replace('16to18','17').replace('3326','30')\n",
    "df['Age'] = df['Age'].replace('1716','117').replace('1735','17').replace('18or20','19').replace('18to22','19').replace('21,34,2435','34').replace('21or26','24').replace('2320','22')\n",
    "df['Age'] = df['Age'].replace('25to35','27').replace('28,2330','28').replace('2826','27').replace('2to3month','1').replace('3032','31').replace('30or36','33').replace('31or33','31').replace('3626','34')\n",
    "df['Age'] = df['Age'].replace('3337','34').replace('33or37','33').replace('3419','34').replace('3623','36').replace('3326','33').replace('37,67,35,27,27','35').replace('4634','46').replace('5030','50')\n",
    "df['Age'] = df['Age'].replace(\"60'\",'60').replace('7or8','7').replace('8or10','9').replace('912','10').replace('9month','1').replace('9or10','9').replace('>50','54').replace('A.M.','0').replace('Both11','11')\n",
    "df['Age'] = df['Age'].replace('Ca.33','33').replace('Elderly','70').replace('F','0').replace('M','0').replace('MAKELINEGREEN','33').replace('Teen','0').replace('X','0').replace('adult','18').replace('mid-20','25').replace('mid-30','35')\n",
    "df['Age'] = df['Age'].replace('nan','0').replace('teen','15').replace('\"45\"','45').replace('\"25\"','25').replace(2, '2').replace('',)     \n",
    "df['Age'] = df['Age'].fillna(2)         \n",
    "         \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# set(df['Age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting column Age to int65\n",
    "df.Age = df.Age.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Age'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set(df['Area'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Area'] = df['Area'].str.replace('�', 'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the len of 10 from the column Case Number as Date_info since we have date to be more in a better shape in it.\n",
    "df['Date_info']=[d[0:10] for d in df['Case Number']]\n",
    "# df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date_info'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the set of values in Date_info to confirm\n",
    "# set(df['Date_info'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting date_info to date format\n",
    "df['Date_info'] =  pd.to_datetime(df['Date_info'], errors='coerce', yearfirst=True, infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date_info'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The final values after converting Date_info to Date format\n",
    "# set(df['Date_info'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:Blue'> By doing errors='coerce' I'm just substituting the cells that cannot be converted (like the ones containing 'ND') with NaN/NaT. But you can also do error='ignore' and handle the weird formats later. For example, there were some formats with days='00'. This is not recognised by 'pandas.to_datetime'. You could do some string operations to make this '00' day to '01' day. A lot of options are possible! :) </span>\n",
    "\n",
    "<span style='color:Blue'> You could now drop the original 'Date' column. You could even compare it against the existing 'Year' column, to see if my suggestion is correct, or at least aligh with the rest of the dataframe ;) </span>\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Date'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# set(df['Location'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Location'] = df['Location'].str.replace('�', ' ').str.replace('?','') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# getitng columns that have null values\n",
    "null = df.isnull().sum()\n",
    "null[null > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    " \n",
    "# df[(df['href formula'].isnull()==True)]\n",
    "# null_href =null_href[['Investigator or Source','Country','Type','Country', 'Area', 'Location','Activity','Name','Sex','Age','Injury','Fatal (Y/N)','Time','href formula','href']]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_inves = df[(df['Investigator or Source'].isnull()==True)]\n",
    "# null_inves = null_inves[['Investigator or Source','Country','Type','Country', 'Area', 'Location','Activity','Name','Sex','Age','Injury','Fatal (Y/N)','Time','href formula']]\n",
    "# null_inves\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set(df['Investigator or Source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.loc[df['Investigator or Source'].isnull()==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i4 out of the 15 NAN from Investigator or Source are not fatal, this means the cases were not reported for investigation.\n",
    "\n",
    "df['Investigator or Source'] = df['Investigator or Source'].fillna('Not reported')\n",
    "df['Investigator or Source'] = df['Investigator or Source'].str.replace('Pacific Commercial Advertiser, 3/24/1850','Pacific Commercial Advertiser').str.replace('Gold Coast Bulletin, 6/4/2016','Gold Coast Bulletin')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confirm =df[(df['Investigator or Source'] == 'Not reported')]\n",
    "# confirm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Species']  = df['Species'].fillna('shark not found')\n",
    "\n",
    "df['Age'] = df['Age'].fillna(0)\n",
    "df['Activity'] = df['Activity'].fillna('Not confirmed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Age'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# To comfirm the changes\n",
    "# set(df['Age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparing the NAN is Country column to the rest of the dataframe\n",
    "null_country = df[(df['Country'].isnull()==True)]\n",
    "null_country = null_country[['Country','Area', 'Location', 'Year','Type','Activity', 'Name', 'Sex', 'Age', 'Injury', 'Fatal','Species', 'Investigator or Source',  'Case Number', 'Original_order']]\n",
    "# null_country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Country = df.Country.fillna('Not confirmed')\n",
    "df.Area = df.Area.fillna('Not confirmed')\n",
    "df.Location = df.Location.fillna('Not confirmed')\n",
    "df['Name'] = df['Name'].fillna('Not confirmed ')\n",
    "df['Sex'] = df['Sex'].fillna('Not confirmed ')\n",
    "df['Injury']=df['Injury'].fillna('Not confirmed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# set(df['Injury'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Injury']  = df['Injury'].str.replace('�','').str.replace('                  PROVOKED INCIDENT','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.loc[df['Injury']=='Probable drowning ', ['Fatal','Injury']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_Injury= df[(df['Injury'].isnull()==True)]\n",
    "null_Injury = null_Injury[['Injury','Fatal','Species','Investigator or Source']]\n",
    "# null_Injury.tail(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft = df[(df['Injury']== 'Puncture wounds to right foot                  PROVOKED INCIDENT')]\n",
    "      \n",
    "ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Injury'] = df['Injury'].replace('No inujury ','No inujury').replace('\"Very severe wounds\"','Very severe wounds').replace('\"Tooth marks\" in left leg','Tooth marks\" in left leg').replace('\"Savagely bitten\"','Savagely bitten').replace('\"Savagely bitten\" but apparently survived','Savagely bitten but apparently survived').replace('\"Mysteriously disappeared\" His body was found in a shark caught at Barber\\'s Point on 01-Sep-1931','Mysteriously disappeared\" His body was found in a shark caught at Barber\\'s Point on 01-Sep-1931')\n",
    "df['Injury'] = df['Injury'].replace(\"No injury to occupants, boat was bumped & lifted 2' out of the water by the shark\",'No injury to occupants, boat was bumped & lifted 2 out of the water by the shark').replace('FATAL            Leg severed by harpooned shark PROVOKED INCIDENT','FATAL Leg severed by harpooned shark PROVOKED INCIDENT').replace('\"Minor cuts to left leg\"','Minor cuts to left leg')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set(df.Name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Name'] = df['Name'].str.replace('Occupant:','').str.replace('�','').str.replace('24 boat Shark Tagger Occupant Keith Poe', 'Keith Poe')\n",
    "df['Name'] = df['Name'].str.replace('\\r\\n','').replace('male, a sponge Diver','sponge Diver').replace(\"a ship's engineer\",'engineer')\n",
    "df['Name'] = df['Name'].replace('American male','American')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Sex', 'Name']].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.loc[:,['Case Number', 'Original_order']].head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# comparing the null values in Fatal to the level of sustained injury to know how to fill it up\n",
    "null_case = df[(df['Fatal'].isnull()==True)]\n",
    "null_case = null_case[['Fatal','Injury']]#,'Case Number', 'Case Number1', 'Case Number2','Investigator or Source', 'Time','Date']]\n",
    "# null_case.tail(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['Injury']=='FATAL', 'Fatal']='Y'\n",
    "df.loc[df['Injury']=='Boat damaged', 'Fatal']='Y'\n",
    "df.loc[df['Injury']=='No injury, no attack', 'Fatal']='N'\n",
    "df.loc[df['Injury']=='No injury', 'Fatal']='Y'\n",
    "df.loc[df['Injury']=='Possible drowning and scavenging', 'Fatal']='Y'\n",
    "df.loc[df['Injury']=='Death preceded shark involvement', 'Fatal']='Y'\n",
    "df.loc[df['Injury']=='Shark caught contained human remains', 'Fatal']='Y'\n",
    "df.loc[df['Injury']=='Shark caught, contained human remains', 'Fatal']='Y'\n",
    "df.loc[df['Injury']=='Probable drowning ', 'Fatal']='Y'\n",
    "df.loc[df['Injury']=='Human remains found in 4m, 900 kg shark', 'Fatal']='Y'\n",
    "df.loc[df['Injury']=='Human remains found in shark', 'Fatal']='Y'\n",
    "df.loc[df['Injury']=='Reported as shark attack but probable drowning', 'Fatal']='Y'\n",
    "df.Fatal = df.Fatal.fillna('N')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# null_case = df[(df['Fatal'].isnull()==True)]\n",
    "# null_case = null_case[['Fatal','Injury']]\n",
    "# null_case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Getting all columns but without the numeric ones\n",
    "df.select_dtypes(exclude=np.number).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data_cleaning.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_df = pd.read_csv('data_cleaning.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
